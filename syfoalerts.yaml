apiVersion: "nais.io/v1alpha1"
kind: "Alert"
metadata:
  name: syfoalerts
  labels:
    team: teamsykefravr
spec:
  receivers:
    slack:
      channel: '#syfo-alerts-prod'
      #prependText: '<!here> | '
  alerts:
    - alert: syfo-app-nede
      expr: up{app=~"syfoarbeidsgivertilgang|syfonarmesteleder|syfoservicestrangler|syfosoknad|syfosyketilfelle|syfosmregler|syfosmregister|syfotekster",job="kubernetes-pods"} == 0
      for: 2m
      description: "{{ $labels.app }} er nede i {{ $labels.kubernetes_namespace }}"
      action: "Se `kubectl describe pod {{ $labels.kubernetes_pod_name }}` for events, og `kubectl logs {{ $labels.kubernetes_pod_name }}` for logger"
      sla: respond within 1h, during office hours
      severity: danger
    - alert: syfo-asynkron-app-nede
      expr: up{app=~"pdf-gen|syfogsak|syfoinntektsmelding|syfosoknadvarsel|syfoaltinn|syfovarsel|syfosmoppgave|syfosmarena|syfosmvarsel|syfosminfotrygd|syfosmsak|syfosmmottak",job="kubernetes-pods"} == 0
      for: 10m
      description: "{{ $labels.app }} er nede i {{ $labels.kubernetes_namespace }}"
      action: "Se `kubectl describe pod {{ $labels.kubernetes_pod_name }}` for events, og `kubectl logs {{ $labels.kubernetes_pod_name }}` for logger"
      sla: respond within 1h, during office hours
      severity: danger
    - alert: syfo-mangler-metrikker
      expr: absent(up{app=~"pdf-gen|syfoarbeidsgivertilgang|syfogsak|syfoinntektsmelding|syfonarmesteleder|syfoservicestrangler|syfosoknadvarsel|syfosoknad|syfosyketilfelle|syfoaltinn|syfovarsel|syfotekster",job="kubernetes-pods"})
      for: 5m
      description: "{{ $labels.app }} rapporterer ingen metrikker i {{ $labels.kubernetes_namespace }}"
      action: "Sjekk om {{ $labels.app }} i {{ $labels.kubernetes_namespace }} er oppe"
      sla: respond within 1h, during office hours
      severity: danger
    - alert: syfosm-mangler-metrikker
      expr: absent(up{app=~"syfosmoppgave|syfosmarena|syfosmvarsel|syfosminfotrygd|syfosmregister|syfosmsak|syfosmmottak|syfosmregler",job="kubernetes-pods"})
      for: 5m
      description: "{{ $labels.app }} rapporterer ingen metrikker i {{ $labels.kubernetes_namespace }}"
      action: "Sjekk om {{ $labels.app }} i {{ $labels.kubernetes_namespace }} er oppe"
      sla: respond within 1h, during office hours
      severity: danger
    - alert: syfosoknadvarsel-lytter-stoppet
      expr: sum(syfosoknadvarsel_kafkalytter_stoppet_total) > 0
      for: 5m
      description: "{{ $labels.app }} sin kafkalytter har stoppet i {{ $labels.kubernetes_namespace }}"
      action: "Kafkalytter stoppet på syfosoknadvarsel. Sjekk logger, og evt. `kubectl delete pod {{ $labels.kubernetes_pod_name }}` for å restarte"
      sla: respond within 1h, during office hours
      severity: danger
    - alert: syfogsak-lytter-stoppet
      expr: sum(syfogsak_kafkalytter_stoppet_total) > 0
      for: 5m
      description: "{{ $labels.app }} sin kafkalytter har stoppet i {{ $labels.kubernetes_namespace }}"
      action: "Kafkalytter stoppet på syfogsak. Sjekk logger, og evt. `kubectl delete pod {{ $labels.kubernetes_pod_name }}` for å restarte"
      sla: respond within 1h, during office hours
      severity: danger
    - alert: syfogsak-ingenSoknaderBehandlet
      expr: sum(increase(syfogsak_innsending_behandlet_total[24h])) < 0.8
      for: 1m
      description: "{{ $labels.app }} har ikke behandlet soknader på 24 timer i {{ $labels.kubernetes_namespace }}"
      action: "Syfogsak har ikke behandlet soknader på 24 timer. Sjekk i errorloggen: https://logs.adeo.no/goto/c117ef2a4003c420e43d391f8007ddda , og evt. `kubectl delete pod {{ $labels.kubernetes_pod_name }}` for å restarte"
      sla: respond within 1h, during office hours
      severity: danger
    - alert: syfovarsel-lytter-stoppet
      expr: sum(syfovarsel_kafkalytter_stoppet_total) > 0
      for: 5m
      description: "{{ $labels.app }} sin kafkalytter har stoppet i {{ $labels.kubernetes_namespace }}"
      action: "Kafkalytter stoppet på syfovarsel. Sjekk logger, og evt. `kubectl delete pod {{ $labels.kubernetes_pod_name }}` for å restarte"
      sla: respond within 1h, during office hours
      severity: danger
    - alert: syfoaltinn-lytter-stoppet
      expr: sum(syfoaltinn_kafkalytter_stoppet_total) > 0
      for: 5m
      description: "{{ $labels.app }} sin kafkalytter har stoppet i {{ $labels.kubernetes_namespace }}"
      action: "Kafkalytter stoppet på syfoaltinn. Sjekk logger, og evt. `kubectl delete pod {{ $labels.kubernetes_pod_name }}` for å restarte"
      sla: respond within 1h, during office hours
      severity: danger
    - alert: syfosyketilfelle-lytter-stoppet
      expr: sum(syfosyketilfelle_kafkalytter_stoppet_total) > 0
      for: 5m
      description: "{{ $labels.app }} sin kafkalytter har stoppet i {{ $labels.kubernetes_namespace }}"
      action: "Kafkalytter stoppet på syfosyketilfelle. Sjekk logger, og evt. `kubectl delete pod {{ $labels.kubernetes_pod_name }}` for å restarte"
      sla: respond within 1h, during office hours
      severity: danger
    - alert: syfoservicestrangler-lytter-stoppet
      expr: sum(syfoservicestrangler_kafkalytter_stoppet_total) > 0
      for: 5m
      description: "{{ $labels.app }} sin kafkalytter har stoppet i {{ $labels.kubernetes_namespace }}"
      action: "Kafkalytter stoppet på syfoservicestrangler. Sjekk logger, og evt. `kubectl delete pod {{ $labels.kubernetes_pod_name }}` for å restarte"
      sla: respond within 1h, during office hours
      severity: danger
    - alert: syfosmvarsel-avvist-sm-usynk
      expr: abs(sum(syfosmvarsel_avvist_sykmelding_mottatt_count) - sum(syfosmvarsel_avvist_sykmelding_opprettetvarsel_count)) > 100
      for: 1h
      description: "Syfosmvarsel har mottatt mange flere avviste sykmeldinger enn det er opprettet varsel for"
      action: "Prosessering av avviste sykmeldinger i smvarsel kan ha stoppet pga feil. Sjekk logger, og evt. `kubectl delete pod {{ $labels.kubernetes_pod_name }}` for å restarte"
      sla: respond within 1h, during office hours
      severity: danger
    - alert: syfosmmottak-ingen-mottatte-sykmeldinger
      expr: sum(increase(syfosmmottak_incoming_message_count[24h])) < 0.8
      for: 1m
      description: "Syfosmmottak har ikke mottatt sykmeldinger på 24 timer"
      action: "Sjekk logger, og evt. `kubectl delete pod {{ $labels.kubernetes_pod_name }}` for å restarte"
      sla: respond within 1h, during office hours
      severity: danger
    - alert: syfosmmottak-ugyldige-sykmeldinger
      expr: sum(syfosmmottak_invalid_message_no_notice_count) > 100
      for: 10m
      description: "Syfosmmottak har mottatt unormalt mange ugyldige sykmeldinger"
      action: "Sjekk logger, og om det kan ha blitt innført feil"
      sla: respond within 1h, during office hours
      severity: danger
    - alert: syfosm-error-logging
      expr: sum(rate(logd_messages_total{log_app=~"syfosmoppgave|syfosmarena|syfosmvarsel|syfosminfotrygd|syfosmregister|syfosmsak|syfosmmottak|syfosmregler",log_level="Error",job="kubernetes-pods"})) > 0
      for: 5m
      description: "{{ $labels.app }} rapporterer error i loggene i {{ $labels.kubernetes_namespace }}"
      action: "Sjekk hvorfor {{ $labels.app }} i {{ $labels.kubernetes_namespace }} logger errors"
      sla: respond within 1h, during office hours
      severity: danger